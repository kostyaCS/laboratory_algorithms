{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree classifier\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "#### We used Iris dataset for this task. It contains 150 samples of 3 different species of Iris flowers (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn package\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR',\n",
       " 'data',\n",
       " 'data_module',\n",
       " 'feature_names',\n",
       " 'filename',\n",
       " 'frame',\n",
       " 'target',\n",
       " 'target_names']"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "dir(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = iris.data, iris.target\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size= 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, X, y, gini, feature_index, left, right, threshold):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.gini = gini\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    \n",
    "    def __init__(self, max_depth):\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def gini(self, groups, classes):\n",
    "        '''\n",
    "        A Gini score gives an idea of how good a split is by how mixed the\n",
    "        classes are in the two groups created by the split.\n",
    "        \n",
    "        A perfect separation results in a Gini score of 0,\n",
    "        whereas the worst case split that results in 50/50\n",
    "        classes in each group result in a Gini score of 0.5\n",
    "        (for a 2 class problem).\n",
    "        '''\n",
    "        dictionary_groups = {}\n",
    "        for element in groups:\n",
    "            if element not in dictionary_groups:\n",
    "                dictionary_groups[element] = 0\n",
    "            dictionary_groups[element] += 1\n",
    "        # print(dictionary_groups)\n",
    "        gini = 1 - sum([(dictionary_groups[group]/len(groups))**2 for group in dictionary_groups])\n",
    "        return gini\n",
    "\n",
    "    def divide(self, X, y,feature, question):\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        true_X, true_y, false_X, false_y = [], [], [], []\n",
    "        for index, value in enumerate(X):\n",
    "            if value[feature] >= question:\n",
    "                true_X.append(value)\n",
    "                true_y.append(y[index])\n",
    "            else:\n",
    "                false_X.append(value)\n",
    "                false_y.append(y[index])\n",
    "        return true_X, true_y, false_X, false_y\n",
    "\n",
    "\n",
    "    def test_divide(self, X, y,feature, question):\n",
    "        true_list, false_list = [], []\n",
    "        for index, value in enumerate(X):\n",
    "            if value[feature] >= question:\n",
    "                true_list.append(y[index])\n",
    "            else:\n",
    "                false_list.append(y[index])\n",
    "        return true_list, false_list\n",
    "\n",
    "    def split_data(self, X, y) -> tuple[int, int]:\n",
    "        impurity = self.gini(y, 0)\n",
    "        questions = set()\n",
    "        for statement in X:\n",
    "            for feature in range(len(X[0])):\n",
    "                true_list, false_list = self.test_divide(X, y, feature, statement[feature])\n",
    "                average_impurity = (len(true_list)/len(X)) * self.gini(true_list, 0) + (len(false_list)/len(X)) * self.gini(false_list, 0)\n",
    "                gain_impurity = impurity - average_impurity\n",
    "                questions.add((feature, statement[feature], gain_impurity))\n",
    "        return sorted(questions, key=lambda x: x[-1])[-1]\n",
    "    \n",
    "    def build_tree(self, X, y, depth = 0):\n",
    "        best_split = self.split_data(X, y)\n",
    "        if best_split[-1] == 0 or depth >= self.max_depth:\n",
    "            return Node(X, y, best_split[-1], best_split[0], None, None, None)\n",
    "        else:\n",
    "            true_X, true_y, false_X, false_y = self.divide(X, y, best_split[0], best_split[1])\n",
    "            true_tree = self.build_tree(true_X, true_y, depth + 1)\n",
    "            false_tree = self.build_tree(false_X, false_y, depth + 1)\n",
    "            return Node(X, y, best_split[-1], best_split[0], true_tree, false_tree, best_split[-2])\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.tree = self.build_tree(X, y)\n",
    "        \n",
    "    def evaluate_probability(self, y_test):\n",
    "        probabilities = {}\n",
    "        for element in y_test:\n",
    "            if element not in probabilities:\n",
    "                probabilities[element] = 0\n",
    "            probabilities[element] += 1\n",
    "        return sorted(probabilities.items(), key=lambda item: item[1])[0][0]\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for sample in X_test:\n",
    "            current_node = self.tree\n",
    "            while True:\n",
    "                if current_node.left is None:\n",
    "                    prediction = self.evaluate_probability(current_node.y)\n",
    "                    predictions.append(prediction)\n",
    "                    break\n",
    "                elif sample[current_node.feature_index] >= current_node.threshold:\n",
    "                    current_node = current_node.left\n",
    "                else:\n",
    "                    current_node = current_node.right\n",
    "        return predictions\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        predictions = self.predict(X_test)\n",
    "        correct_predictions = sum([1 for i in range(len(y_test)) if y_test[i] == predictions[i]])\n",
    "        return correct_predictions / len(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class functions\n",
    "1) fit - function, which builds tree (build_tree) and sets result into class variable tree\n",
    "2) build_tree - recursive function which builds composition of Node objects using test_divide and gini function.\n",
    "3) test_divide - function which tests how good divide and returns information gain index.\n",
    "4) gini - function which returns gini index.\n",
    "6) divide - function which divides tree for given feature\n",
    "7) evaluate_probability - function which returns most common type. \n",
    "8) predict - function which returns predictions for given list of features.\n",
    "9) evaluate - function, which returns how acurate are given predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "clf = MyDecisionTreeClassifier(10)\n",
    "clf.fit(X_test, y_test)\n",
    "print(clf.evaluate(X, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
